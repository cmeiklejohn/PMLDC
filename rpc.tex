\subsection{Relevant Reading}

%% TODO: Cite The isis project: Real experience with a fault tolerant programming system.
%% TODO: Cite Exploiting virtual synchrony in distributed systems.
%% TODO: Implementing remote procedure calls.
%% TODO: Distribution and abstract types in emerald.
%% TODO: Using time instead of timeout for fault-tolerant distributed systems.
%% TODO: Distributed programming in argus.
%% TODO: Implementing fault-tolerant services using the state machine approach: A tutorial
%% TODO: A distributed object model for the java system.

\begin{itemize}
	\item \textit{A Note On Distributed Computing}, Kendall, Waldo, Wollrath, Wyant, 1994~\cite{kendall1994note}.
	\item \textit{It's Just A Mapping Problem}, Vinoski, 2003~\cite{vinoski2003s}.
	\item \textit{Convenience Over Correctness}, Vinoski, 2008~\cite{vinoski2008convenience}.
\end{itemize}

\subsection{Commentary}

\begin{quote}
``Does developer convenience really trump correctness, scalability,performance, separation of concerns, extensibility, and accidentalcomplexity?''~\cite{vinoski2008convenience}
\end{quote}

\subsubsection{Timeline}

\begin{itemize}

\item{1974:} RFC 674, \\ ``Procedure Call Protocol Documents, Version 2''

\item{1975:} RFC 684, \\ ``A Commentary on Procedure Calling as a Network Protocol''
%% 1975, RPC 684, share resources with all 70 notes of the internet - Bolt, Barek and Newman, later Genuity, which has ASN 1 and is one of the oldest functioning networks of the internet
%% basically states the problem about distributed systems *then*, but we haven't learned in 30+ years "deja-vu", never get it right, leaky abstraction

\item{1976:} RFC 707, \\ ``A High-Level Framework for Network-Based Resource Sharing''
%% RFC 707 defines a protocol that we want -- discusses telnet and how we can "mechanize" it

\item{1984:} ``Implementing Remote Procedure Calls''
%% 1984: sunrpc defined

\item{1987:} Distribution and Abstract Types in Emerald
%% VMS programming language; types for distributed computing, call by move, calling conventions, copy the data on the wire, first use of distributed objects.

\item{1988:} Distributed Programing in Argus
%% barbara liskov, "guardians" moves between nodes, resurrect on failed nodes; atomicity through the guardians, coordination with rollback, each function is going to have a rollback mechanism

\item{1988:} RFC 1057, \\ ``Remote Procedure Call Protocol Specification, Version 2''
%% defines sunrpc as a standard, make a function call across the network, portmap, etc.  used for NFS.

\item{1991:} CORBA 1.0
%% distributed objects

\item{1996:} ``A Distributed Object Model for the Java System''
%% corba, waldo, introduces RMI (oak story, etc.)

\item{1997:} CORBA 2.0
%% major corba release

\item{1999+:} EJB, XML-RPC, SOAP, REST
%% modern day standardized RPC mechanisms

\end{itemize}

\subsubsection{Overview}

Remote Procedure Call (RPC) is a general term for executing a subroutine in a different address space without writing the actual code used to perform the remote execution.	To provide an example, we can imagine a user wishing to invoke the random number generator function on another machine, but, the only difference between the local and remote invocation is supplying an additional node identifier where it should occur.  While not the first implementation, because it was preceded by Apollo Computer's Network Computing System (NCS), the first major implementation to be widely known and adopted was the SunRPC mechanism, from Sun Microsystems, used to back their Network File System (NFS).

Remote Procedure Call mechanisms you may be more familiar with are Java's Remote Method Invocation (RMI), it's predecessor Modula-3's Network Objects, XML-RPC, SOAP, CORBA, Avro, Facebook's, (now Apache) Thrift, Google's Protocol Buffers, and Twitter's Finagle.

\subsubsection{RFC 684}

\begin{quote}
``Rather, we take exception to PCPâ€™s underlying premise: that the procedure calling discipline is the starting point for building multi-computer systems.''	
\end{quote}

RFC 684 is commentary on RFC 674 that introduced the Procedure Call Paradigm, Version 2 (PCP).  This commentary highlights, what boils down to, three major points from a critical analysis of the Procedure Call Paradigm. 

\begin{itemize}
	\item Procedure calling is usually a primitive operation; by primitive, it should be an extremely fast context switch operation performed by the underlying abstraction.
	\item Local and remote calls each have different cost profiles; remote calls can be delayed, and in the event of failure,  may \textbf{never return}.
	\item Asynchronous message passing, or sending a message and waiting for a response when the response is needed, is a much better model because it makes the passing of messages \textbf{explicit}.
\end{itemize}

Following from these three points, we see a series of concerns develop about this programming paradigm, all of which become a common theme across the 40+ years in RPC's history.  These are:

\begin{itemize}
	\item Difficulty in recovery after malfunction or error.  For instance, do we rollback or throw exceptions?  How do we handle these errors?  Can we just try again?  
	%% TODO: Ousterhaut's RFIL, Liskov's Promises.
	\item Difficulty in sequencing operations.  If all calls are synchronous and some of these calls can fail, it can require a significant amount of code to ensure correct re-execution to preserve order moving forward. 
	\item Remote Procedure Call forces \textbf{synchronous programming}: a method is invoked and the invoking process waits for a response.
	\item Backpressure, or blocking on previous actions completing, load-shedding, or dropping messages on the floor when the system is overloaded, and priority servicing become more difficult with the call-and-response model of Remote Procedure Call.
\end{itemize}

\subsubsection{RFC 707}

\begin{quote}
``Because of this cost differential, the applications programmer must exercise discretion in his use of remote resources, even though the mechanics of their use will have been greatly simplified by the RTE. Like virtual memory, the procedure call model offers great convenience, and therefore power, in exchange for reasonable alertness to the possibilities of abuse.''
\end{quote}

RFC 707 generalizes the ideas from RFC 684 and discusses the problem of resources sharing for services such as TELNET and FTP: each of these services presents a \textit{different} interface for interacting with it, which requires the operator to know the specific protocol for interacting with that service.  In realizing that both services like TELNET and FTP follow the call-and-response model, the authors propose an alternative idea: rather than needing to know all of the available commands and protocols on the remote machine, can we define a generic interface for executing a remote procedure that takes an argument list and follows the call-and-response model?

While we can, the problems of control flow and priority servicing outlined in RFC 684 remain; however, not enough that it prevents this model from being adopted by many systems in the future.

%% TODO: Emerald and objects needs to go before this.

\subsubsection{CORBA}

%% replicated objects: state machine replication, ISIS, virtual synchrony
%% live objects: distinct identities, encapsulate their own state, CORBA, DCOM

The Common Object Request Broker Architecture (CORBA) is an abstraction for object-oriented languages, popularized by C++, that allows you to communicate between different languages and different address spaces running on different machines.  CORBA relied on the use of an Interface Definition Language (IDL) for specifying the interfaces of remote classes of objects; this IDL was used to generate stubs of what the remote systems object interfaces appeared as on the local machine.  These IDL's would be used to generate mappings between the abstract interfaces provided by the IDL's and the actual implementations in languages such as C++ and Java.

%% TODO: Add citation.
CORBA attempted to provide several benefits to the application developer: language independence, OS-independence, architecture-independence, static typing through a mapping of abstract types in the IDL to machine and language specific implementations of those types, and object transfer, where objects can be migrated  over the wire between different machines.  CORBA's promise was that through the use of mapping that remote calls could appear as local calls, and that distributed systems related exceptions could be mapped into local exceptions and handled by local exception handling mechanisms.  

However, as Vinoski points out in 2003, the evaluation of programming languages and abstractions based on transparency alone is flawed:

\begin{quote}
``The goal is to merge middleware abstractions directly into the realm of the programming language, minimizing the impedance mismatch between the programming language world and the middleware world. For example, mappings make request invocations on distributed objects and services appear as normal programming-language function calls, and they map distributed system exceptions into native programming language exception-handling mechanisms.''~\cite{vinoski2003s}
\end{quote}

\subsubsection{``A Note On Distributed Computing''}

\begin{quote}
``It is the thesis of this note that this unified view of objects is mistaken.''~\cite{kendall1994note}
\end{quote}

In this pinnacle Waldo paper, they argue that "it is perilous to ignore the differences" between local and distributed computing and that the unified view of objects is flawed.~\cite{kendall1994note}  They cite two independent groups of work, the systems of Emerald and Argus, and the modern equivalents of those systems, Microsoft's DCOM and OMG's CORBA: all systems that  extended the RPC mechanism to objects and method invocation.

%Objects have interfaces defined by the IDL
%The RPC mechanism is extended to objects and method invocation
%Abstracts over how the remote call will actually be issued -- programmer doesn't see the communication or perform the binding
%Local and remote calls are just not the same!
%But, we've already know all this!

We can summarize the ``promise'' of the unified view of objects, as Waldo does in the paper.

\begin{itemize}
\item Applications are designed using interfaces on the local machine.
\item Objects are relocated, because of the transparency of location, to gain the desired application performance.
\item The application is then tested with ``real bullets.''
\end{itemize}

This strategy for the design of a distributed application has two fundamental flaws.  First, that the design of an application can be done with interfaces alone, and that this design will be discovered during the development of the application.  Second, that application correctness does not depend on object location, but only the interfaces to each object.

Waldo swats down this design with the ``three false principles''~\cite{kendall1994note}:

\begin{quote}
``there is a single natural object-oriented design for a givenapplication, regardless of the context in which that applicationwill be deployed''
\end{quote}

\begin{quote}
``failure and performance issues are tied to the implementation ofthe components of an application, and consideration of theseissues should be left out of an initial design''
\end{quote}

\begin{quote}
```the interface of an object is independent of the context in whichthat object is used''
\end{quote}

\subsubsection{``Every 10 years...''}

\begin{quote}
``The hard problems in distributed computing are not the problems of getting things on and off the wire.''~\cite{kendall1994note}
\end{quote}

Waldo argues that every ten years we approach the problem of attempting to unify the view of local and remote computing and run into the same problems, again and again: \textbf{local and remote computing are fundamentally different.}

\paragraph{Latency} Waldo argues that the most obvious difference should be the issues of latency: if you ignore latency, you will end up directly impacting software performance.  He states that is it wrong to ``rely on steadily increasing speed of the underlying hardware'' and that it is not always possible to test with ``real bullets''.  Performance analysis and relocation is non-trivial and a design that is optimal at one point will not necessarily stay optimal.

\paragraph{Memory Access} His criticisms of memory access are very specific to CORBA and its predecessors in the object space: objects can retain pointers to objects in the same address space, but once moved these pointers will no longer be valid.  He states that one approach to solving the problem is distributed shared memory, but more practically techniques such as marshalling or replacement by CORBA references, which are marshalled for distributed access, are used.

\paragraph{Partial Failure} Finally, the most fundamental problem: partial failure.  In local computing, he argues, failures are detectable, total, and result in a return of control.  This is not true with distributed computing: independent components may fail, failures are partial and a failure of a link is indistinguishable from a failure of a remote processor.

As always, Waldo says it best:

\begin{quote}
``The question is not `can you make remote method invocation look like local method invocation?' but rather `what is the price of making remote method invocation identical to local method invocation?'''~\cite{kendall1994note}
\end{quote}

Waldo argues that there is only two paths forward if we want to achieve the goal of the unified object model.

\begin{itemize}
\item Treat all objects as local.
\item Treat all objects as remote.
\end{itemize}

However, he states that if the real goal is to ``make distributed computing as simple as local computing'', that the only real path forward is the first.  This approach, he believes, is flawed, and that distribution is fundamentally different, and must be treated so.

\begin{quote}
``This approach would also defeat the overall purpose of unifyingthe object models. The real reason for attempting such aunification is to make distributed computing more like localcomputing and thus make distributed computing easier. Thissecond approach to unifying the models makes local computingas complex as distributed computing.''~\cite{kendall1994note}	
\end{quote}

The paper provides two examples of where this paradigm is problematic, but we will highlight one case, that builds upon RPC.

\subsubsection{Network File System}

Sun Microsystem's \textbf{Network File System (NFS)}, built upon RPC, is one of the first distributed file systems to gain popularity.  Network File System adhered to the existing filesystem API, but introduced an entire new class of failures resulting from network partitions, partial failure, and high latency.  Network File System is a stateless protocol implemented in UDP; the decision to implement it this way is motivated by the perceived ease in debugging protocols that do not carry state.

Network File System operated in two modes: soft mounting and hard mounting.  Soft mounting introduced a series of new error codes related to the additional ways file operations could fail: these error codes were not known by existing UNIX applications and led to smaller adoption of this approach.  Hard mounting introduced the opposite behavior for failures related to the network: \textbf{operations would block until they could be completed successfully}.  

\textit{It's just a mapping problem, right?}~\cite{vinoski2003s}

\subsubsection{``Convenience Over Correctness''}

\begin{quote}
``We have a general-purpose imperative programming-languagehammer, so we treat distributed computing as just another nail tobend to fit the programming models.''~\cite{vinoski2008convenience}
\end{quote}

Vinoski highlights three very important points in ``Convenience Over Correctness'' criticism of RPC many years later.

\begin{itemize}
\item \textbf{Interface Definition Languages (IDL) ``impedance mismatch''}: base types may be easy to map, but more complex types may be less so.
\item \textbf{Scalability:} the RPC paradigm does not have any first class support for caching, or mechanisms for mitigating high latency, and is remains a rather primitive operation to build distributed applications with.
\item \textbf{Representational State Transfer (REST)}: REST is good: it specifically addresses the problem of managing distributed resources; but most frameworks built on top of REST alter the abstraction and present something that repeats the problem~\footnote{For instance, if one was to build an object model on top of REST.}.	 
\end{itemize}

\subsection{Impact and Implementations}

Remote Procedure Call (RPC) has been around for a very long time and while many opponents of RPC have been extremely critical of it, it still remains one of the most widely used way of writing distributed applications.  There's an unprecedented amount of use of frameworks for RPC like Twitter's Finagle, Google's Protocol Buffers, and Apache's Thrift deployed and used in production applications every day.  

Newer frameworks, such as Google's gRPC for HTTP/2.0 continue to reduce the amount of complexity in building applications with them, attempting to bring RPC to an even wider audience.  These frameworks claim that since they do not attempt to hide that the calls are remote, that it is a better abstraction.  However, now we have returned to the aforementioned problem of soft mounting in NFS: explicitly handling the flow control from the array of possible network exceptions that could occur.

But, the question we have to ask ourselves is whether the abstraction of an individual method invocation or function call is the correct paradigm for building distributed applications.  Is the idea of treating all remote objects as local, and making distribution as transparent as possible, the correct decision moving forward?  Does it mask failure modes that will allow developers to build applications that will not operate correctly under partial failure?

When we talk about distributed programming languages today, many developers equate this to \textbf{programming languages} that can be, and have been used, to build \textbf{distributed systems.}  For example, any language with concurrency primitives and the ability to open a network socket would suffice to build these systems; this does not imply that these languages are distributed programming languages.

But, a \textbf{distributed programming language} is where the  distribution is \textbf{first class}.  Languages like Go are more closely related to \textbf{concurrent} languages, where concurrency is first class; and, while concurrency is a requirement for distribution, these are different topics.  CORBA is an example of trying to make distribution first class in languages such as C++.

Erlang~\cite{claessen2005semantics, svensson2007more, svensson2007programming} is one language where distribution is first class.  Erlang has a RPC mechanism, but prefers the use of asynchronous message passing between processes.  In fact, the RPC mechanism in Erlang is implemented using Erlang's native asynchronous message passing.  While you can peek under the covers and see \textbf{where} processes are running, Erlang tries to make the programmer assume that each process could be executing on a different node.  Motivated by the expressiveness of the design, both Distributed Process, from the Cloud Haskell group, and Akka, in Scala, are examples that attempt to bring Erlang-style semantics to Haskell and Scala, respectively.

One approach taken in the Scala community for distributed programming is serializable closures~\cite{miller2014spores}, or what's known as the function shipping paradigm.  In this model, entire functions are moved across the network, where the type system is used to ensure that all of values in scope can be properly serialized or marshalled as these closures move across the network.  While this solves some of the problematic points in systems like CORBA and DCOM, it does not have a solution for the problem of how to ensure exacty-once execution of functions, or to handle partial failure where you can not distinguish the failure of the remote node from the network.

Languages like Bloom, and Bloom\textsubscript{L}, and Lasp~\cite{alvaro2011consistency, conway2012logic, meiklejohn2015lasp} take an alternative approach: can we build abstractions that rely on asynchronous programming, very weak ordering and structuring our applications in such a way where they are tolerant to network anomalies such as message duplication and message re-ordering.  While this approach is more expensive in terms of state transmission, and more restrictive in what types of computations can be expressed, this style of programming supports the creation of \textit{correct-by-construction} distributed applications.  These applications are highly tolerant to anomalies resulting from network failures by assuming all actors in the system are distributed.  The restrictions, however, might prohibit wide adoption of these techniques.

So, we ask again:

\begin{quote}
``Does developer convenience really trump correctness, scalability,performance, separation of concerns, extensibility, and accidentalcomplexity?''~\cite{vinoski2008convenience}
\end{quote}

\clearpage